# Loading and running models from C

We want a light-weight library to load into larger applications that only need to execute the tensorflow models. Building a C++ application that links to the standard tensorflow install requires adding it to the bazel build system, which is intractable for 

The static library produced by 
[https://github.com/FloopCZ/tensorflow_cc](https://github.com/FloopCZ/tensorflow_cc)
results in a 100MB executable to just say helloworld! That's too much.
The static library is only for C++ as well, which might be a problem trying to link to a Fortran program.
(Well, to be fair, the problem is Fortran.)
The compilation also didn't work on macOS, yielding unknown instruction errors for the vector operations.
The TensorFlow build scripts don't have a dedicated mac version.
It's not a big deal because I like to run in Docker on mac anyways, but there is another solution.


TensorFlow provides a slimmed down  precompiled library with an API for C:
[https://www.tensorflow.org/install/install_c](https://www.tensorflow.org/install/install_c)
libtensorflow.so is only 49MB and lets us go with the dynamic linking option. There are precompiled options for macOS, too, but I haven't tried them yet.

## Loading a graph

The meta graphs don't work in the C API because apparently they have some Python elements. Instead, we have
to serialize the graph into the protobuf description. I had to add a line to the end of the model_loading
notebook to write it out differently,
```python
gd=graph5.as_graph_def()
from tensorflow.python.platform import gfile
with gfile.GFile("trimmed.pb", "w") as f:
	f.write(gd.SerializeToString())
```
The protobuf files can be loaded by the C API. The file [load_graph.c](load_graph.c) is the first working
example I found from
[stackoverflow](https://stackoverflow.com/questions/41688217/how-to-load-a-graph-with-tensorflow-so-and-c-api-h-in-c-language), credited to user `ash`.


## Executing a graph

After some more digging, I found some more [example code on StackOverflow](https://stackoverflow.com/questions/44305647/segmentation-fault-when-using-tf-sessionrun-to-run-tensorflow-graph-in-c-not-c) that builds on that last bit of code, credited to user `DrBBQ`. (StackOverflow is truly the modern way of learning libraries.) 
 

## Statefullness of Our Computations

We eventually want to put this ability into computational kernels, like those generated by
[Popcorn](https://github.com/afqueiruga/popcorn).
However, Popcorn has a strict no-side-effect, stateless policy to the kernels.
Strictly adhering to that policy would demand that the kernels constantly open and close tensorflow sessions
and read from the file.
That's obviously a horrible inefficiency and not at all how tensorflow is designed to be used.
The kernels will have to deviate from this pureness and add a scratch buffer and have state information.
I was already thinking about this for kernels that call GSL, which requires some preallocated data structs
for scratch space, e.g. the perumation vector for calling LU.
Every spawned thread from cornflakes will have to allocate an independent scratch buffer, and kernels will
have to define some sort of autogenerated struct that maps onto the buffer.
I hate the idea of changing the kernel eval routine to have a `*ctx` pointer though!!! Ughh.
